{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "type": "object",
    "required": [
        "general",
        "mcp",
        "plugins",
        "ui"
    ],
    "properties": {
        "general": {
            "type": "object",
            "required": [
                "llm",
                "embeddings",
                "speech_to_text",
                "text_to_speech",
                "hardware_acceleration"
            ],
            "properties": {
                "architecture": {
                    "type": "object",
                    "required": ["mode"],
                    "properties": {
                        "mode": {
                            "type": "string",
                            "enum": ["threads", "processes"],
                            "description": "Architecture mode: 'threads' for LocalBus, 'processes' for BullMQBus"
                        }
                    },
                    "additionalProperties": false
                },
                "llm": {
                    "type": "object",
                    "required": [
                        "provider",
                        "third_party",
                        "local"
                    ],
                    "properties": {
                        "provider": {
                            "type": "string",
                            "enum": [
                                "openai",
                                "huggingface_endpoint",
                                "huggingface_pipeline",
                                "llama_cpp"
                            ],
                            "description": "LLM provider to use",
                            "ui_choices": [
                                "llama_cpp",
                                "openai",
                                "huggingface_endpoint",
                                "huggingface_pipeline"
                            ]
                        },
                        "third_party": {
                            "type": "object",
                            "required": [
                                "openai",
                                "huggingface_endpoint"
                            ],
                            "properties": {
                                "openai": {
                                    "type": "object",
                                    "required": [
                                        "options"
                                    ],
                                    "properties": {
                                        "options": {
                                            "type": "object",
                                            "required": [
                                                "model",
                                                "temperature",
                                                "max_tokens"
                                            ],
                                            "properties": {
                                                "model": {
                                                    "type": "string",
                                                    "description": "OpenAI model to use",
                                                    "ui_choices": [
                                                        "gpt-4o",
                                                        "gpt-4",
                                                        "gpt-3.5-turbo",
                                                        "gpt-4-turbo",
                                                        "gpt-4.1",
                                                        "gpt-5-mini",
                                                        "gpt-5-nano"
                                                    ]
                                                },
                                                "temperature": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 2,
                                                    "description": "Sampling temperature for OpenAI models"
                                                },
                                                "max_tokens": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "maximum": 4096,
                                                    "description": "Maximum tokens for OpenAI responses"
                                                }
                                            },
                                            "additionalProperties": false
                                        }
                                    },
                                    "additionalProperties": false
                                },
                                "huggingface_endpoint": {
                                    "type": "object",
                                    "required": [
                                        "options"
                                    ],
                                    "properties": {
                                        "options": {
                                            "type": "object",
                                            "required": [
                                                "endpoint_url",
                                                "model",
                                                "access_token",
                                                "temperature",
                                                "max_tokens"
                                            ],
                                            "properties": {
                                                "endpoint_url": {
                                                    "type": "string",
                                                    "description": "HuggingFace endpoint URL"
                                                },
                                                "model": {
                                                    "type": "string",
                                                    "description": "HuggingFace model name"
                                                },
                                                "access_token": {
                                                    "type": "string",
                                                    "description": "HuggingFace access token"
                                                },
                                                "temperature": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 2,
                                                    "description": "Sampling temperature"
                                                },
                                                "max_tokens": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "maximum": 4096,
                                                    "description": "Maximum tokens for responses"
                                                }
                                            },
                                            "additionalProperties": false
                                        }
                                    },
                                    "additionalProperties": false
                                }
                            },
                            "additionalProperties": false
                        },
                        "local": {
                            "type": "object",
                            "required": [
                                "huggingface_pipeline",
                                "llama_cpp"
                            ],
                            "properties": {
                                "huggingface_pipeline": {
                                    "type": "object",
                                    "required": [
                                        "options"
                                    ],
                                    "properties": {
                                        "options": {
                                            "type": "object",
                                            "required": [
                                                "model"
                                            ],
                                            "properties": {
                                                "model": {
                                                    "type": "string",
                                                    "description": "HuggingFace model name for local pipeline"
                                                },
                                                "temperature": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 2,
                                                    "description": "Sampling temperature"
                                                },
                                                "max_tokens": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "description": "Maximum tokens for responses"
                                                },
                                                "torch_dtype": {
                                                    "type": "string",
                                                    "enum": [
                                                        "auto",
                                                        "float32",
                                                        "float16",
                                                        "bfloat16"
                                                    ],
                                                    "description": "PyTorch data type",
                                                    "ui_choices": [
                                                        "auto",
                                                        "float32",
                                                        "float16",
                                                        "bfloat16"
                                                    ]
                                                },
                                                "device": {
                                                    "type": "string",
                                                    "enum": [
                                                        "cpu",
                                                        "cuda",
                                                        "auto"
                                                    ],
                                                    "description": "Device to run the model on",
                                                    "ui_choices": [
                                                        "cpu",
                                                        "cuda",
                                                        "auto"
                                                    ]
                                                },
                                                "pipeline_kwargs": {
                                                    "type": "object"
                                                },
                                                "model_kwargs": {
                                                    "type": "object"
                                                }
                                            },
                                            "additionalProperties": true
                                        }
                                    },
                                    "additionalProperties": false
                                },
                                "llama_cpp": {
                                    "type": "object",
                                    "required": [
                                        "options"
                                    ],
                                    "properties": {
                                        "options": {
                                            "type": "object",
                                            "required": [
                                                "model_path",
                                                "temperature",
                                                "max_tokens",
                                                "n_ctx",
                                                "n_gpu_layers",
                                                "n_batch",
                                                "top_p",
                                                "top_k",
                                                "repeat_penalty",
                                                "min_p"
                                            ],
                                            "properties": {
                                                "model_path": {
                                                    "type": "string",
                                                    "description": "Path to the GGUF model file",
                                                    "ui_type": "file",
                                                    "ui_file_filter": "GGUF files (*.gguf)|*.gguf|All files (*.*)|*.*"
                                                },
                                                "temperature": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 2,
                                                    "description": "Sampling temperature for Llama.cpp"
                                                },
                                                "max_tokens": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "maximum": 4096,
                                                    "description": "Maximum tokens for responses"
                                                },
                                                "n_ctx": {
                                                    "type": "integer",
                                                    "minimum": 512,
                                                    "maximum": 32768,
                                                    "description": "Context window size"
                                                },
                                                "n_gpu_layers": {
                                                    "type": "integer",
                                                    "minimum": 0,
                                                    "maximum": 100,
                                                    "description": "Number of layers to offload to GPU"
                                                },
                                                "n_batch": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "maximum": 2048,
                                                    "description": "Batch size for processing"
                                                },
                                                "top_p": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 1,
                                                    "description": "Top-p sampling parameter"
                                                },
                                                "top_k": {
                                                    "type": "integer",
                                                    "minimum": 1,
                                                    "maximum": 200,
                                                    "description": "Top-k sampling parameter"
                                                },
                                                "repeat_penalty": {
                                                    "type": "number",
                                                    "minimum": 0.1,
                                                    "maximum": 2.0,
                                                    "description": "Repetition penalty"
                                                },
                                                "min_p": {
                                                    "type": "number",
                                                    "minimum": 0,
                                                    "maximum": 1,
                                                    "description": "Minimum probability threshold"
                                                },
                                                "chat_format": {
                                                    "type": "string",
                                                    "enum": [
                                                        "chatml",
                                                        "chatml-function-calling",
                                                        "llama-2",
                                                        "alpaca",
                                                        "vicuna"
                                                    ],
                                                    "description": "Chat format template to use",
                                                    "ui_choices": [
                                                        "chatml",
                                                        "chatml-function-calling",
                                                        "llama-2",
                                                        "alpaca",
                                                        "vicuna"
                                                    ]
                                                }
                                            },
                                            "additionalProperties": true
                                        }
                                    },
                                    "additionalProperties": false
                                }
                            },
                            "additionalProperties": false
                        }
                    },
                    "additionalProperties": false
                },
                "embeddings": {
                    "type": "object",
                    "required": [
                        "use_local"
                    ],
                    "properties": {
                        "use_local": {
                            "type": "boolean",
                            "description": "Use local embeddings model instead of API"
                        }
                    },
                    "additionalProperties": false
                },
                "speech_to_text": {
                    "type": "object",
                    "required": [
                        "language",
                        "ambient_transcription"
                    ],
                    "properties": {
                        "architecture": {
                            "type": "object",
                            "required": ["use_streaming", "legacy_mode"],
                            "properties": {
                                "use_streaming": {
                                    "type": "boolean",
                                    "description": "Use new streaming STT architecture"
                                },
                                "legacy_mode": {
                                    "type": "boolean",
                                    "description": "Enable legacy monolithic STT mode"
                                }
                            },
                            "additionalProperties": false
                        },
                        "language": {
                            "type": "string",
                            "enum": [
                                "",
                                "en",
                                "pt",
                                "es",
                                "fr",
                                "de",
                                "it",
                                "ja",
                                "ko",
                                "zh"
                            ],
                            "description": "Language for speech recognition (empty for auto-detect)",
                            "ui_choices": [
                                "",
                                "en",
                                "pt",
                                "es",
                                "fr",
                                "de",
                                "it",
                                "ja",
                                "ko",
                                "zh"
                            ]
                        },
                        "ambient_transcription": {
                            "type": "object",
                            "required": [
                                "enable",
                                "chunk_duration",
                                "storage_path",
                                "filter_short_transcriptions",
                                "min_transcription_length"
                            ],
                            "properties": {
                                "enable": {
                                    "type": "boolean",
                                    "description": "Enable ambient transcription"
                                },
                                "chunk_duration": {
                                    "type": "number", 
                                    "minimum": 0.5, 
                                    "maximum": 60.0,
                                    "description": "Duration in seconds of audio chunks to process"
                                },
                                "storage_path": {
                                    "type": "string",
                                    "description": "Directory path for file storage"
                                },
                                "filter_short_transcriptions": {
                                    "type": "boolean",
                                    "description": "Filter out short transcriptions to reduce noise"
                                },
                                "min_transcription_length": {
                                    "type": "integer", 
                                    "minimum": 0,
                                    "description": "Minimum character length for transcriptions when filtering"
                                }
                            },
                            "additionalProperties": false
                        },
                        "audio_input": {
                            "type": "object",
                            "properties": {
                                "device_index": {
                                    "type": ["integer", "null"],
                                    "description": "Audio input device index (null for default)"
                                },
                                "sample_rate": {
                                    "type": "integer",
                                    "enum": [8000, 16000, 22050, 44100, 48000],
                                    "description": "Audio sample rate in Hz"
                                },
                                "channels": {
                                    "type": "integer",
                                    "minimum": 1,
                                    "maximum": 2,
                                    "description": "Number of audio channels"
                                },
                                "chunk_size": {
                                    "type": "integer",
                                    "minimum": 128,
                                    "maximum": 8192,
                                    "description": "Audio chunk size in frames"
                                },
                                "format": {
                                    "type": "string",
                                    "enum": ["int16", "int32", "float32"],
                                    "description": "Audio sample format"
                                }
                            },
                            "additionalProperties": false
                        },
                        "wake_word": {
                            "type": "object",
                            "properties": {
                                "enabled": {
                                    "type": "boolean",
                                    "description": "Enable wake word detection"
                                },
                                "backend": {
                                    "type": "string",
                                    "enum": ["oww", "pvp"],
                                    "description": "Wake word backend: 'oww' (OpenWakeWord) or 'pvp' (Porcupine)"
                                },
                                "model_path": {
                                    "type": ["string", "null"],
                                    "description": "Path to wake word model file"
                                },
                                "threshold": {
                                    "type": "number",
                                    "minimum": 0.0,
                                    "maximum": 1.0,
                                    "description": "Wake word detection threshold"
                                },
                                "inference_framework": {
                                    "type": "string",
                                    "enum": ["onnx", "tflite"],
                                    "description": "Inference framework for wake word detection"
                                }
                            },
                            "additionalProperties": false
                        },
                        "transcription": {
                            "type": "object",
                            "properties": {
                                "vad_enabled": {
                                    "type": "boolean",
                                    "description": "Enable voice activity detection"
                                },
                                "vad_threshold": {
                                    "type": "number",
                                    "minimum": 0.0,
                                    "maximum": 1.0,
                                    "description": "VAD threshold"
                                },
                                "silence_duration_ms": {
                                    "type": "integer",
                                    "minimum": 100,
                                    "maximum": 5000,
                                    "description": "Silence duration in milliseconds before stopping"
                                },
                                "max_speech_duration_s": {
                                    "type": "integer",
                                    "minimum": 5,
                                    "maximum": 300,
                                    "description": "Maximum speech duration in seconds"
                                },
                                "realtime_model": {
                                    "type": "object",
                                    "properties": {
                                        "enabled": {
                                            "type": "boolean",
                                            "description": "Enable realtime transcription model"
                                        },
                                        "model_size": {
                                            "type": "string",
                                            "enum": ["tiny", "base", "small", "medium", "large"],
                                            "description": "Whisper model size for realtime transcription"
                                        },
                                        "device": {
                                            "type": "string",
                                            "enum": ["cpu", "cuda", "auto"],
                                            "description": "Device for realtime model"
                                        },
                                        "compute_type": {
                                            "type": "string",
                                            "enum": ["int8", "int16", "float16", "float32"],
                                            "description": "Compute type for realtime model"
                                        }
                                    },
                                    "additionalProperties": false
                                },
                                "accurate_model": {
                                    "type": "object",
                                    "properties": {
                                        "enabled": {
                                            "type": "boolean",
                                            "description": "Enable accurate transcription model"
                                        },
                                        "model_size": {
                                            "type": "string",
                                            "enum": ["tiny", "base", "small", "medium", "large"],
                                            "description": "Whisper model size for accurate transcription"
                                        },
                                        "device": {
                                            "type": "string",
                                            "enum": ["cpu", "cuda", "auto"],
                                            "description": "Device for accurate model"
                                        },
                                        "compute_type": {
                                            "type": "string",
                                            "enum": ["int8", "int16", "float16", "float32"],
                                            "description": "Compute type for accurate model"
                                        }
                                    },
                                    "additionalProperties": false
                                }
                            },
                            "additionalProperties": false
                        },
                        "coordinator": {
                            "type": "object",
                            "properties": {
                                "session_timeout_s": {
                                    "type": "number",
                                    "minimum": 1.0,
                                    "maximum": 300.0,
                                    "description": "Session timeout in seconds"
                                },
                                "multi_turn_enabled": {
                                    "type": "boolean",
                                    "description": "Enable multi-turn conversation"
                                },
                                "pause_tts_on_listen": {
                                    "type": "boolean",
                                    "description": "Pause TTS when listening for speech"
                                }
                            },
                            "additionalProperties": false
                        }
                    },
                    "additionalProperties": false
                },
                "text_to_speech": {
                    "type": "object",
                    "required": [
                        "model_file_path",
                        "model_config_file_path",
                        "model_sample_rate",
                        "piper_path"
                    ],
                    "properties": {
                        "model_file_path": {
                            "type": "string",
                            "description": "Path to the TTS model file",
                            "ui_type": "file",
                            "ui_file_filter": "ONNX files (*.onnx)|*.onnx|All files (*.*)|*.*"
                        },
                        "model_config_file_path": {
                            "type": "string",
                            "description": "Path to the TTS model configuration file",
                            "ui_type": "file",
                            "ui_file_filter": "Text files (*.txt)|*.txt|All files (*.*)|*.*"
                        },
                        "model_sample_rate": {
                            "type": "integer",
                            "minimum": 8000,
                            "maximum": 48000,
                            "description": "Sample rate for TTS output"
                        },
                        "piper_path": {
                            "type": "string",
                            "description": "Path to Piper TTS executable",
                            "ui_type": "file",
                            "ui_file_filter": "Executable files (*.exe)|*.exe|All files (*.*)|*.*"
                        }
                    },
                    "additionalProperties": false
                },
                "hardware_acceleration": {
                    "type": "object",
                    "required": [
                        "tts",
                        "stt",
                        "ocr_bg",
                        "ocr_curr",
                        "llm"
                    ],
                    "properties": {
                        "tts": {
                            "type": "boolean",
                            "description": "Enable hardware acceleration for TTS"
                        },
                        "stt": {
                            "type": "boolean",
                            "description": "Enable hardware acceleration for STT"
                        },
                        "ocr_bg": {
                            "type": "boolean",
                            "description": "Enable hardware acceleration for background OCR"
                        },
                        "ocr_curr": {
                            "type": "boolean",
                            "description": "Enable hardware acceleration for current OCR"
                        },
                        "llm": {
                            "type": "boolean",
                            "description": "Enable hardware acceleration for LLM"
                        }
                    },
                    "additionalProperties": false
                }
            },
            "additionalProperties": false
        },
        "plugins": {
            "type": "object",
            "required": [
                "google",
                "jira",
                "openrecall",
                "brave_search",
                "github",
                "slack",
                "gmail",
                "gcalendar"
            ],
            "properties": {
                "google": {
                    "type": "object",
                    "required": [
                        "credentials_file"
                    ],
                    "properties": {
                        "credentials_file": {
                            "type": "string",
                            "description": "Path to Google credentials JSON file",
                            "ui_type": "file",
                            "ui_file_filter": "JSON files (*.json)|*.json|All files (*.*)|*.*"
                        }
                    },
                    "additionalProperties": false
                },
                "jira": {
                    "type": "object",
                    "required": [
                        "activate",
                        "api_token",
                        "username",
                        "instance_url"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable Jira integration"
                        },
                        "api_token": {
                            "type": "string",
                            "description": "Jira API token"
                        },
                        "username": {
                            "type": "string",
                            "description": "Jira username"
                        },
                        "instance_url": {
                            "type": "string",
                            "format": "uri",
                            "description": "Jira instance URL"
                        }
                    },
                    "additionalProperties": false
                },
                "openrecall": {
                    "type": "object",
                    "required": [
                        "activate"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable OpenRecall integration"
                        }
                    },
                    "additionalProperties": false
                },
                "brave_search": {
                    "type": "object",
                    "required": [
                        "activate",
                        "api_key"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable Brave Search integration"
                        },
                        "api_key": {
                            "type": "string",
                            "description": "Brave Search API key"
                        }
                    },
                    "additionalProperties": false
                },
                "github": {
                    "type": "object",
                    "required": [
                        "activate",
                        "app_id",
                        "app_private_key",
                        "repository"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable GitHub integration"
                        },
                        "app_id": {
                            "type": "string",
                            "description": "GitHub App ID"
                        },
                        "app_private_key": {
                            "type": "string",
                            "description": "GitHub App private key"
                        },
                        "repository": {
                            "type": "string",
                            "description": "GitHub repository"
                        }
                    },
                    "additionalProperties": false
                },
                "slack": {
                    "type": "object",
                    "required": [
                        "activate",
                        "user_token"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable Slack integration"
                        },
                        "user_token": {
                            "type": "string",
                            "description": "Slack user token"
                        }
                    },
                    "additionalProperties": false
                },
                "gmail": {
                    "type": "object",
                    "required": [
                        "activate"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable Gmail integration"
                        }
                    },
                    "additionalProperties": false
                },
                "gcalendar": {
                    "type": "object",
                    "required": [
                        "activate"
                    ],
                    "properties": {
                        "activate": {
                            "type": "boolean",
                            "description": "Enable Google Calendar integration"
                        }
                    },
                    "additionalProperties": false
                }
            },
            "additionalProperties": false
        },
        "mcp": {
            "type": "object",
            "required": [
                "enabled",
                "servers"
            ],
            "properties": {
                "enabled": {
                    "type": "boolean",
                    "description": "Enable Model Context Protocol integration"
                },
                "servers": {
                    "type": "object",
                    "description": "MCP server configurations indexed by server name",
                    "patternProperties": {
                        "^[a-zA-Z][a-zA-Z0-9_-]*$": {
                            "type": "object",
                            "description": "MCP server configuration",
                            "properties": {
                                "enabled": {
                                    "type": "boolean",
                                    "description": "Enable or disable this MCP server",
                                    "default": true
                                },
                                "transport": {
                                    "type": "string",
                                    "enum": [
                                        "stdio",
                                        "streamable_http",
                                        "sse",
                                        "websocket"
                                    ],
                                    "description": "Transport protocol for MCP communication. 'stdio' runs a local process",
                                    "ui_choices": [
                                        "stdio",
                                        "streamable_http", 
                                        "sse",
                                        "websocket"
                                    ]
                                },
                                "command": {
                                    "type": "string",
                                    "description": "Command to start the MCP server (required for stdio transport)"
                                },
                                "args": {
                                    "type": "array",
                                    "description": "Arguments to pass to the command (used with stdio transport)",
                                    "items": {
                                        "type": "string"
                                    },
                                    "default": []
                                },
                                "url": {
                                    "type": "string",
                                    "format": "uri",
                                    "description": "URL endpoint for HTTP-based transports (required for streamable_http, sse, websocket)"
                                },
                                "headers": {
                                    "type": "object",
                                    "description": "Custom HTTP headers for authentication and configuration (supported by streamable_http, sse, websocket). For Atlassian servers, consider using stdio transport with mcp-remote instead of manual authentication.",
                                    "patternProperties": {
                                        "^.+$": {
                                            "type": "string"
                                        }
                                    },
                                    "default": {}
                                },
                                "env": {
                                    "type": "object",
                                    "description": "Environment variables for the MCP server process (used with stdio transport)",
                                    "patternProperties": {
                                        "^.+$": {
                                            "type": "string"
                                        }
                                    },
                                    "default": {}
                                },
                                "cwd": {
                                    "type": "string",
                                    "description": "Working directory for the MCP server process (used with stdio transport)"
                                },
                                "timeout": {
                                    "type": "number",
                                    "description": "Connection timeout in seconds",
                                    "minimum": 1,
                                    "maximum": 300,
                                    "default": 30
                                }
                            },
                            "required": [
                                "transport"
                            ],
                            "allOf": [
                                {
                                    "if": {
                                        "properties": {
                                            "transport": {
                                                "const": "stdio"
                                            }
                                        }
                                    },
                                    "then": {
                                        "required": [
                                            "command",
                                            "args"
                                        ],
                                        "not": {
                                            "required": [
                                                "url"
                                            ]
                                        }
                                    }
                                },
                                {
                                    "if": {
                                        "properties": {
                                            "transport": {
                                                "enum": [
                                                    "streamable_http",
                                                    "sse", 
                                                    "websocket"
                                                ]
                                            }
                                        }
                                    },
                                    "then": {
                                        "required": [
                                            "url"
                                        ],
                                        "not": {
                                            "required": [
                                                "command",
                                                "args"
                                            ]
                                        }
                                    }
                                }
                            ],
                            "additionalProperties": false
                        }
                    },
                    "additionalProperties": false
                }
            },
            "additionalProperties": false
        },
        "ui": {
            "type": "object",
            "required": [
                "activate",
                "dark_mode",
                "debug"
            ],
            "properties": {
                "activate": {
                    "type": "boolean",
                    "description": "Enable graphical user interface"
                },
                "dark_mode": {
                    "type": "boolean",
                    "description": "Enable dark mode theme"
                },
                "debug": {
                    "type": "boolean",
                    "description": "Enable debug mode for verbose logging"
                }
            },
            "additionalProperties": false
        },
        "messaging": {
            "type": "object",
            "properties": {
                "redis": {
                    "type": "object",
                    "properties": {
                        "url": {
                            "type": "string",
                            "format": "uri",
                            "description": "Redis connection URL for BullMQ message bus"
                        }
                    },
                    "additionalProperties": false
                },
                "priorities": {
                    "type": "object",
                    "properties": {
                        "interactive": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 100,
                            "description": "Priority level for interactive messages"
                        },
                        "system": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 100,
                            "description": "Priority level for system messages"
                        },
                        "external": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 100,
                            "description": "Priority level for external messages"
                        }
                    },
                    "additionalProperties": false
                }
            },
            "additionalProperties": false
        }
    },
    "additionalProperties": false
}